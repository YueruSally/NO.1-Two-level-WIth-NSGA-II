#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Two-Level NSGA-II for Multi-batch Multimodal Transportation
- Upper level: NSGA-II to build an OD→route pool (batch-agnostic)
- Lower level: batch allocation + feasibility checks (capacity/timetables/time windows) with bottleneck feedback
- Objectives: cost / emissions / completion time
- Data: reads from extended.xlsx; if sea legs/feeders are missing, common trunks are auto-injected
- Output: optimisation_results.txt (Pareto overview + detailed allocation + full route decomposition)
"""

import os
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from enum import IntEnum
import random
import copy
from collections import defaultdict, deque
import math
import re

# =========================
# Routing/policy hyperparameters (bias towards sea)
# =========================
ROAD_MAX_KM   = 350.0   # Max single road leg distance in kilometres (>350 km not considered; road used as short drayage)
PUNISH_ROAD   = 80.0    # Penalty per road leg
REWARD_RAIL   = 10.0    # Reward per rail leg
REWARD_WATER  = 40.0    # Reward per water leg

# Ports & extra handling times (hours)
PORT_HANDLING_H        = 36.0   # Per port call (load/unload on one side)
RAIL_BORDER_GAUGE_H    = 12.0   # Break-of-gauge handling (e.g., Brest/Malaszewicze)

# Port whitelists (used if Excel lacks explicit port flags)
SEA_PORTS_CN = {
    "Shanghai","Ningbo","Qingdao","Tianjin","Dalian","Xiamen",
    "Shenzhen","Guangzhou","Lianyungang","Yantian","Shekou","Nansha"
}
SEA_PORTS_EU = {
    "Hamburg","Rotterdam","Antwerp","Zeebrugge","Bremerhaven",
    "Gdansk","Gdynia","Koper","Piraeus","Gioia Tauro","Gothenburg","Felixstowe"
}

# =========================
# Model symbols (aligned with Table II)
# =========================

class Mode(IntEnum):
    """Transport modes M = {1: road, 2: rail, 3: waterway}"""
    ROAD = 1
    RAIL = 2
    WATER = 3

@dataclass
class NetworkParameters:
    """Parameters matching Table II notation"""
    L_ij: Dict[Tuple[str, str], float] = field(default_factory=dict)
    CAP_node: Dict[str, float] = field(default_factory=dict)       # TEU/h
    CAP_border: Dict[str, float] = field(default_factory=dict)
    rho: Dict[str, str] = field(default_factory=dict)
    M: float = 1e6
    I_border: Dict[Tuple[str, str], bool] = field(default_factory=dict)
    B_j: Dict[str, bool] = field(default_factory=dict)
    C_ijm: Dict[Tuple[str, str, Mode], float] = field(default_factory=dict)
    TC_jmn: Dict[Tuple[str, Mode, Mode], float] = field(default_factory=dict)
    W_hold: Dict[str, float] = field(default_factory=dict)
    W_proc: Dict[str, float] = field(default_factory=dict)
    W_cong: Dict[str, float] = field(default_factory=dict)
    P_k: Dict[int, float] = field(default_factory=dict)
    CT_r: Dict[str, float] = field(default_factory=dict)
    Theta_rm: Dict[Tuple[str, Mode], float] = field(default_factory=dict)
    E_mr: Dict[Tuple[Mode, str], float] = field(default_factory=dict)
    V_m: Dict[Mode, float] = field(default_factory=dict)
    TT_jmn: Dict[Tuple[str, Mode, Mode], float] = field(default_factory=dict)
    BD_j: Dict[str, float] = field(default_factory=dict)
    CC_j: Dict[str, float] = field(default_factory=dict)
    S_jm: Dict[Tuple[str, Mode], List[float]] = field(default_factory=dict)   # Weekly departure times (hours, 0–168)
    arc_modes: Dict[Tuple[str, str], List[Mode]] = field(default_factory=dict)

@dataclass
class Batch:
    """Batch k ∈ K with parameters from Table II"""
    id: int
    O_k: str
    DEST_k: str
    Q_k: float
    ET_k: float
    LT_k: float

@dataclass
class DecisionVariables:
    """Primary decision variables from Table II"""
    f_ijmk: Dict[Tuple[str, str, Mode, int], float] = field(default_factory=dict)
    z_ijmk: Dict[Tuple[str, str, Mode, int], float] = field(default_factory=dict)

@dataclass
class AuxiliaryVariables:
    """Auxiliary variables from Table II"""
    y_jmnk: Dict[Tuple[str, Mode, Mode, int], float] = field(default_factory=dict)
    t_max: float = 0.0
    a_jk: Dict[Tuple[str, int], float] = field(default_factory=dict)  # arrival time at node j
    d_jk: Dict[Tuple[str, int], float] = field(default_factory=dict)  # departure time at node j
    q_jmk: Dict[Tuple[str, Mode, int], float] = field(default_factory=dict)
    w_jk: Dict[Tuple[str, int], float] = field(default_factory=dict)
    p_jk: Dict[Tuple[str, int], float] = field(default_factory=dict)
    delta_k: Dict[int, float] = field(default_factory=dict)

# ===== Original model: objective evaluation =====

class MultimodalOptimizationModel:
    """Implementation of the mathematical model"""
    def __init__(self, params: NetworkParameters, network: dict, batches: List[Batch]):
        self.params = params
        self.network = network
        self.batches = batches
        self.nodes = set(network['nodes'].keys())
        self.arcs = network['arcs']

    def determine_transshipment_volumes(self, decision_vars: DecisionVariables) -> Dict:
        """Derive y_jmnk (transhipment volumes) from flow variables"""
        y_jmnk = {}
        for batch in self.batches:
            k = batch.id
            for j in self.nodes:
                if j == batch.O_k or j == batch.DEST_k:
                    continue
                incoming = defaultdict(float)
                outgoing = defaultdict(float)
                for (i, j2), arc_data in self.arcs.items():
                    if j2 == j:
                        for m in arc_data.get('modes', []):
                            key = (i, j, m, k)
                            if key in decision_vars.f_ijmk:
                                incoming[m] += decision_vars.f_ijmk[key]
                    if i == j:
                        for m in arc_data.get('modes', []):
                            key = (j, j2, m, k)
                            if key in decision_vars.f_ijmk:
                                outgoing[m] += decision_vars.f_ijmk[key]
                for m in Mode:
                    for n in Mode:
                        if m != n:
                            y_val = min(incoming[m], outgoing[n])
                            if y_val > 0:
                                y_jmnk[(j, m, n, k)] = y_val
        return y_jmnk

    def calculate_objective_1(self, decision_vars: DecisionVariables, aux_vars: AuxiliaryVariables) -> float:
        """Minimise total cost"""
        total_cost = 0.0
        for batch in self.batches:
            k = batch.id
            transport_cost = 0.0
            for (i, j), arc_data in self.arcs.items():
                for m in arc_data.get('modes', []):
                    key = (i, j, m, k)
                    if key in decision_vars.f_ijmk:
                        distance = arc_data.get('distances', {}).get(m, 0.0)
                        unit_cost = self.params.C_ijm.get((i, j, m), 1.5)
                        transport_cost += unit_cost * distance * decision_vars.f_ijmk[key]
            transship_cost = 0.0
            for (j, m, n, k2), y_value in aux_vars.y_jmnk.items():
                if k2 == k and m != n:
                    tc = self.params.TC_jmn.get((j, m, n), 50.0)
                    transship_cost += tc * y_value
            carbon_cost = 0.0
            for (i, j), arc_data in self.arcs.items():
                for m in arc_data.get('modes', []):
                    key = (i, j, m, k)
                    if key in decision_vars.f_ijmk:
                        region = self.params.rho.get(i, 'CN')
                        ct = self.params.CT_r.get(region, 10.0)
                        theta = self.params.Theta_rm.get((region, m), 1.0)
                        ef = self.params.E_mr.get((m, region), 0.05)
                        distance = arc_data.get('distances', {}).get(m, 0.0)
                        carbon_cost += ct * theta * ef * distance * decision_vars.f_ijmk[key]
            waiting_cost = 0.0
            for (j, k2), w_time in aux_vars.w_jk.items():
                if k2 == k:
                    total_flow_at_j = sum(
                        decision_vars.f_ijmk.get((i, j, m, k), 0.0)
                        for (i, j2), arc_data in self.arcs.items() if j2 == j
                        for m in arc_data.get('modes', [])
                    )
                    w_hold = self.params.W_hold.get(j, 2.0)
                    waiting_cost += w_hold * total_flow_at_j * w_time
            for (j, k2), p_time in aux_vars.p_jk.items():
                if k2 == k:
                    total_flow_at_j = sum(
                        decision_vars.f_ijmk.get((i, j, m, k), 0.0)
                        for (i, j2), arc_data in self.arcs.items() if j2 == j
                        for m in arc_data.get('modes', [])
                    )
                    w_proc = self.params.W_proc.get(j, 5.0)
                    waiting_cost += w_proc * total_flow_at_j * p_time
            for (j, m, k2), q_time in aux_vars.q_jmk.items():
                if k2 == k:
                    total_flow = sum(
                        decision_vars.f_ijmk.get((i, j, m, k), 0.0)
                        for (i, j2), _ in self.arcs.items() if j2 == j
                    )
                    w_cong = self.params.W_cong.get(j, 10.0)
                    waiting_cost += w_cong * total_flow * q_time
            delta = aux_vars.delta_k.get(k, 0.0)
            p_k = self.params.P_k.get(k, 20.0)
            tardiness_cost = p_k * batch.Q_k * delta
            total_cost += transport_cost + transship_cost + carbon_cost + waiting_cost + tardiness_cost
        return total_cost

    def calculate_objective_2(self, decision_vars: DecisionVariables) -> float:
        """Minimise total carbon emissions"""
        total_emissions = 0.0
        for batch in self.batches:
            k = batch.id
            for (i, j), arc_data in self.arcs.items():
                for m in arc_data.get('modes', []):
                    key = (i, j, m, k)
                    if key in decision_vars.f_ijmk:
                        region = self.params.rho.get(i, 'CN')
                        ef = self.params.E_mr.get((m, region), 0.05)
                        distance = arc_data.get('distances', {}).get(m, 0.0)
                        total_emissions += ef * distance * decision_vars.f_ijmk[key]
        return total_emissions

    def calculate_objective_3(self, aux_vars: AuxiliaryVariables) -> float:
        """Minimise completion time"""
        return aux_vars.t_max

# =========================
# Two-level framework data structures
# =========================

@dataclass
class RouteSegment:
    nodes: List[str]       # e.g. [Xi'an, Khorgos, ... , Berlin]
    modes: List[Mode]      # len = len(nodes)-1

@dataclass
class PortfolioChromosome:
    """Upper-level chromosome: a small route pool per (O,D) (batch-agnostic)"""
    route_pool: Dict[Tuple[str, str], List[RouteSegment]] = field(default_factory=dict)

@dataclass
class AllocationResult:
    feasible: bool
    dv: DecisionVariables
    aux: AuxiliaryVariables
    objectives: Tuple[float, float, float]
    bottleneck_nodes: List[str] = field(default_factory=list)
    late_batches: List[int] = field(default_factory=list)

# =========================
# Lower-level allocation & feasibility
# =========================

class LowerLevelAllocator:
    def __init__(self, model: MultimodalOptimizationModel, plan_horizon_h: float = 168.0):
        self.model = model
        self.params = model.params
        self.network = model.network
        self.plan_horizon_h = plan_horizon_h  # Approximate rolling window (hours)

    def evaluate(self, chrom: PortfolioChromosome) -> AllocationResult:
        dv = DecisionVariables()
        aux = AuxiliaryVariables()

        # Batch priority: tighter due dates (small LT) and larger volumes first
        batches_sorted = sorted(
            self.model.batches,
            key=lambda b: (b.LT_k - b.ET_k, -b.Q_k)
        )

        node_load: Dict[str, float] = defaultdict(float)
        bottlenecks: Set[str] = set()
        late_batches: List[int] = []

        for b in batches_sorted:
            key = (b.O_k, b.DEST_k)
            cand_routes = chrom.route_pool.get(key, [])
            if not cand_routes:
                bottlenecks.add(b.O_k)
                continue

            # Route scoring: penalise road, reward rail/sea
            def score_route(r: RouteSegment) -> float:
                length = self._route_distance(r)
                road_legs  = sum(1 for m in r.modes if m == Mode.ROAD)
                rail_legs  = sum(1 for m in r.modes if m == Mode.RAIL)
                water_legs = sum(1 for m in r.modes if m == Mode.WATER)
                bias = PUNISH_ROAD*road_legs - REWARD_RAIL*rail_legs - REWARD_WATER*water_legs
                return length + bias

            routes_sorted = sorted(cand_routes, key=score_route)

            parts = []  # (route, flow)
            remaining = b.Q_k

            for route in routes_sorted:
                if remaining <= 1e-6:
                    break
                cap_ok, min_headroom, viol_nodes = self._check_capacity_margin(route, remaining, node_load)
                if not cap_ok:
                    if min_headroom > 1e-6:
                        use = max(0.0, 0.8 * min_headroom)
                        if use > 1e-6:
                            parts.append((route, use))
                            self._accumulate_node_load(route, use, node_load)
                            remaining -= use
                            bottlenecks.update(viol_nodes)
                    else:
                        bottlenecks.update(viol_nodes)
                    continue
                # Timetable presence (soft warning only)
                sched_missing = self._check_timetable_presence(route)
                if sched_missing:
                    bottlenecks.update(sched_missing)
                # Allocate full remainder
                use = min(remaining, b.Q_k)
                parts.append((route, use))
                self._accumulate_node_load(route, use, node_load)
                remaining -= use

            if remaining > 1e-6:
                for n in routes_sorted[0].nodes:
                    bottlenecks.add(n)
                continue

            # Convert to decision variables
            for route, flow in parts:
                self._inject_route_flow_to_dv(b.id, route, flow, dv)

        if len(dv.f_ijmk) == 0:
            aux = AuxiliaryVariables()
            return AllocationResult(
                feasible=False, dv=dv, aux=aux,
                objectives=(1e15, 1e12, 1e9),
                bottleneck_nodes=sorted(bottlenecks),
                late_batches=[]
            )

        # Timing & objectives
        aux.y_jmnk = self.model.determine_transshipment_volumes(dv)
        self._calculate_temporal_variables_light(dv, aux)

        # Mark late batches
        for b in self.model.batches:
            arrive = 0.0
            for (j_k, k), t in aux.a_jk.items():
                if k == b.id and j_k == b.DEST_k:
                    arrive = max(arrive, t)
            if arrive - b.LT_k > 1e-6:
                late_batches.append(b.id)

        obj1 = self.model.calculate_objective_1(dv, aux)
        obj2 = self.model.calculate_objective_2(dv)
        obj3 = self.model.calculate_objective_3(aux)

        feasible = len(bottlenecks) == 0
        return AllocationResult(
            feasible=feasible,
            dv=dv,
            aux=aux,
            objectives=(obj1, obj2, obj3),
            bottleneck_nodes=sorted(bottlenecks),
            late_batches=late_batches
        )

    # ---- helpers ----

    def _route_distance(self, r: RouteSegment) -> float:
        d = 0.0
        for i in range(len(r.nodes)-1):
            a, b = r.nodes[i], r.nodes[i+1]
            m = r.modes[i]
            arc = self.network['arcs'].get((a, b), {})
            d += arc.get('distances', {}).get(m, 0.0)
        return d

    def _check_capacity_margin(self, r: RouteSegment, flow: float,
                               node_load: Dict[str, float]) -> Tuple[bool, float, List[str]]:
        """
        Approximate capacity check:
        processed volume within plan_horizon_h must be ≤ CAP_node[j] * plan_horizon_h
        Returns: (fits, min headroom, violating nodes)
        """
        violating = []
        headrooms = []
        for j in r.nodes:
            cap_h = self.params.CAP_node.get(j, 1e9)
            limit = cap_h * self.plan_horizon_h
            used = node_load.get(j, 0.0)
            headroom = max(0.0, limit - used)
            headrooms.append(headroom)
            if used + flow > limit + 1e-6:
                violating.append(j)
        if violating:
            return False, min(headrooms) if headrooms else 0.0, violating
        return True, min(headrooms) if headrooms else 1e9, []

    def _accumulate_node_load(self, r: RouteSegment, flow: float, node_load: Dict[str, float]):
        for j in r.nodes:
            node_load[j] += flow

    def _check_timetable_presence(self, r: RouteSegment) -> List[str]:
        """If a node lacks rail/sea timetable, flag as potential bottleneck (soft)"""
        missing = []
        for i in range(len(r.nodes)-1):
            j = r.nodes[i]
            m = r.modes[i]
            if m in (Mode.RAIL, Mode.WATER):
                if (j, m) not in self.params.S_jm:
                    missing.append(j)
        return missing

    def _inject_route_flow_to_dv(self, k: int, r: RouteSegment, flow: float, dv: DecisionVariables):
        for i in range(len(r.nodes)-1):
            a, b = r.nodes[i], r.nodes[i+1]
            m = r.modes[i]
            key = (a, b, m, k)
            dv.f_ijmk[key] = dv.f_ijmk.get(key, 0.0) + flow
            dv.z_ijmk[key] = 1.0

    def _calculate_temporal_variables_light(self, dv: DecisionVariables, aux: AuxiliaryVariables):
        """
        Lightweight timing:
        - Road: depart immediately
        - Rail/Sea: if timetable exists, depart at earliest feasible service; otherwise, depart immediately
        - Add processing at transhipment/border/port: TT_jmn / BD_j / CC_j / PORT_HANDLING_H / RAIL_BORDER_GAUGE_H
        """
        params = self.params
        arcs = self.network['arcs']
        for b in self.model.batches:
            k = b.id
            aux.a_jk[(b.O_k, k)] = b.ET_k
            dest_arrival = 0.0

            # Build local graph for this batch
            graph = defaultdict(list)
            for (i, j, m, k2), flow in dv.f_ijmk.items():
                if k2 == k and flow > 0:
                    graph[i].append((j, m, flow))
            q = deque([(b.O_k, b.ET_k)])
            visited = set([b.O_k])

            while q:
                node, arrive_time_at_node = q.popleft()
                aux.a_jk[(node, k)] = max(aux.a_jk.get((node, k), 0.0), arrive_time_at_node)

                # Processing time (mode change/border/port)
                process_time = 0.0
                out_modes = set(m for (_, m, _) in graph.get(node, []))

                # Generic mode-change time (if multiple modes present)
                if len(out_modes) >= 2:
                    process_time = max(
                        [params.TT_jmn.get((node, m1, m2), 0.0)
                         for m1 in out_modes for m2 in out_modes if m1 != m2] + [0.0]
                    )

                # Border processing (customs/clearance)
                if params.B_j.get(node, False):
                    process_time += params.BD_j.get(node, 0.0) + params.CC_j.get(node, 0.0)
                    if Mode.RAIL in out_modes:
                        process_time += RAIL_BORDER_GAUGE_H

                # Port handling if WATER is involved
                if self.network['nodes'].get(node, {}).get('is_port', False):
                    if Mode.WATER in out_modes:
                        process_time += PORT_HANDLING_H

                for (nxt, m, flow) in graph.get(node, []):
                    # Departure time
                    if m in (Mode.RAIL, Mode.WATER):
                        schedules = params.S_jm.get((node, m), [])
                        ready_time = aux.a_jk[(node, k)] + process_time
                        if schedules:
                            mod = ready_time % 168
                            valid = [s for s in schedules if s >= mod]
                            if valid:
                                dep = ready_time - mod + min(valid)
                            else:
                                dep = ready_time - mod + 168 + schedules[0]
                        else:
                            dep = ready_time
                    else:
                        dep = aux.a_jk[(node, k)] + process_time

                    aux.d_jk[(node, k)] = dep
                    arc = arcs.get((node, nxt), {})
                    dist = arc.get('distances', {}).get(m, 0.0)
                    speed = params.V_m.get(m, 50.0)
                    travel = dist / speed if speed > 0 else 0.0
                    arrive_next = dep + travel
                    aux.a_jk[(nxt, k)] = max(aux.a_jk.get((nxt, k), 0.0), arrive_next)

                    if nxt == b.DEST_k:
                        dest_arrival = max(dest_arrival, arrive_next)

                    if nxt not in visited:
                        visited.add(nxt)
                        q.append((nxt, aux.a_jk[(nxt, k)]))

            aux.delta_k[k] = max(0.0, dest_arrival - b.LT_k)
            aux.t_max = max(aux.t_max, dest_arrival)

# =========================
# Upper-level Two-Level NSGA-II (strategic)
# =========================

class TwoLevelNSGA2:
    def __init__(self, model: MultimodalOptimizationModel,
                 batches: List[Batch],
                 pop_size: int = 30,
                 n_generations: int = 50,
                 crossover_prob: float = 0.9,
                 mutation_prob: float = 0.25,
                 max_paths_per_od: int = 3):
        self.model = model
        self.params = model.params
        self.network = model.network
        self.batches = batches
        self.pop_size = pop_size
        self.n_generations = n_generations
        self.crossover_prob = crossover_prob
        self.mutation_prob = mutation_prob
        self.max_paths_per_od = max_paths_per_od
        self.lower = LowerLevelAllocator(model)
        self.od_pairs = sorted({(b.O_k, b.DEST_k) for b in batches})

    # ---- Path search (strategic, batch-agnostic) ----
    def _road_allowed(self, i: str, j: str, dist_km: float) -> bool:
        """Allow road only for short drayage; cross-region road must touch a border node"""
        if dist_km is None or dist_km <= 0:
            return False
        if dist_km > ROAD_MAX_KM:
            return False
        nodes = self.network['nodes']
        ri = nodes.get(i, {}).get('region', '')
        rj = nodes.get(j, {}).get('region', '')
        if ri != rj:
            if not (nodes.get(i, {}).get('is_border', False) or nodes.get(j, {}).get('is_border', False)):
                return False
        return True

    def find_paths(self, origin: str, dest: str, max_paths: int = 12, max_hops: int = 10) -> List[RouteSegment]:
        arcs = self.network['arcs']
        paths: List[RouteSegment] = []

        def dfs(node: str, nodes: List[str], modes: List[Mode]):
            if len(paths) >= max_paths:
                return
            if node == dest and len(nodes) > 1:
                paths.append(RouteSegment(nodes=list(nodes), modes=list(modes)))
                return
            if len(nodes) > max_hops:
                return
            for (i, j), arc_data in arcs.items():
                if i != node or j in nodes:
                    continue
                for m in arc_data.get('modes', []):
                    if m == Mode.ROAD:
                        dist = arc_data.get('distances', {}).get(Mode.ROAD, None)
                        if not self._road_allowed(i, j, dist):
                            continue
                    nodes.append(j)
                    modes.append(m)
                    dfs(j, nodes, modes)
                    nodes.pop()
                    modes.pop()

        dfs(origin, [origin], [])
        return paths

    def generate_initial_population(self) -> List[PortfolioChromosome]:
        pop = []
        for _ in range(self.pop_size):
            pool: Dict[Tuple[str, str], List[RouteSegment]] = {}
            for (o, d) in self.od_pairs:
                cand = self.find_paths(o, d, max_paths=12)
                if cand:
                    k = min(self.max_paths_per_od, len(cand))
                    pool[(o, d)] = random.sample(cand, k)
                else:
                    pool[(o, d)] = []
            pop.append(PortfolioChromosome(route_pool=pool))
        return pop

    def evaluate(self, chrom: PortfolioChromosome) -> AllocationResult:
        return self.lower.evaluate(chrom)

    # ---- Genetic operators ----
    def crossover(self, p1: PortfolioChromosome, p2: PortfolioChromosome) -> PortfolioChromosome:
        child_pool: Dict[Tuple[str, str], List[RouteSegment]] = {}
        for od in self.od_pairs:
            routes1 = p1.route_pool.get(od, [])
            routes2 = p2.route_pool.get(od, [])
            def sig(r: RouteSegment) -> Tuple[Tuple[str, ...], Tuple[int, ...]]:
                return (tuple(r.nodes), tuple(int(m) for m in r.modes))
            merged, seen = [], set()
            for r in (routes1 + routes2):
                s = sig(r)
                if s not in seen:
                    seen.add(s)
                    merged.append(r)
            if merged:
                k = min(self.max_paths_per_od, len(merged))
                child_pool[od] = random.sample(merged, k)
            else:
                child_pool[od] = []
        return PortfolioChromosome(route_pool=child_pool)

    def mutate(self, chrom: PortfolioChromosome, bottlenecks: List[str]) -> PortfolioChromosome:
        if not bottlenecks or random.random() > self.mutation_prob:
            return copy.deepcopy(chrom)
        mutated = copy.deepcopy(chrom)
        bad = set(bottlenecks)
        for od in self.od_pairs:
            cur = mutated.route_pool.get(od, [])
            cand_all = self.find_paths(od[0], od[1], max_paths=16)
            avoid = [r for r in cand_all if not any(n in bad for n in r.nodes)]
            new_list = []
            for r in cur:
                if any(n in bad for n in r.nodes) and avoid:
                    new_list.append(random.choice(avoid))
                else:
                    new_list.append(r)
            if not avoid and cand_all:
                for i in range(len(new_list)):
                    if random.random() < 0.3:
                        new_list[i] = random.choice(cand_all)
            if len(new_list) > self.max_paths_per_od:
                new_list = random.sample(new_list, self.max_paths_per_od)
            mutated.route_pool[od] = new_list
        return mutated

    # ---- Non-dominated sorting + crowding distance ----
    @staticmethod
    def dominates(o1: Tuple[float, float, float], o2: Tuple[float, float, float]) -> bool:
        better = False
        for i in range(3):
            if o1[i] > o2[i]:
                return False
            if o1[i] < o2[i]:
                better = True
        return better

    def non_dominated_sort(self, objs: List[Tuple[float, float, float]]) -> List[List[int]]:
        n = len(objs)
        S = [[] for _ in range(n)]
        n_dom = [0]*n
        fronts = [[]]
        for p in range(n):
            for q in range(n):
                if p == q: continue
                if self.dominates(objs[p], objs[q]):
                    S[p].append(q)
                elif self.dominates(objs[q], objs[p]):
                    n_dom[p] += 1
            if n_dom[p] == 0:
                fronts[0].append(p)
        i = 0
        while fronts[i]:
            nxt = []
            for p in fronts[i]:
                for q in S[p]:
                    n_dom[q] -= 1
                    if n_dom[q] == 0:
                        nxt.append(q)
            i += 1
            fronts.append(nxt)
        return [f for f in fronts if f]

    @staticmethod
    def crowding_distance(front_indices: List[int], objs: List[Tuple[float, float, float]]) -> List[float]:
        if not front_indices:
            return []
        distances = [0.0]*len(front_indices)
        nobj = 3
        local = [objs[i] for i in front_indices]
        for m in range(nobj):
            order = sorted(range(len(local)), key=lambda t: local[t][m])
            distances[order[0]] = float('inf')
            distances[order[-1]] = float('inf')
            minv = local[order[0]][m]
            maxv = local[order[-1]][m]
            if abs(maxv - minv) < 1e-12:
                continue
            for idx in range(1, len(local)-1):
                prev_val = local[order[idx-1]][m]
                next_val = local[order[idx+1]][m]
                distances[order[idx]] += (next_val - prev_val) / (maxv - minv)
        return distances

    def run(self) -> List[Tuple[DecisionVariables, Tuple[float, float, float]]]:
        print(f"Starting Two-Level NSGA-II: pop={self.pop_size}, gen={self.n_generations}")
        population = self.generate_initial_population()
        last_eval: List[AllocationResult] = [None]*len(population)

        for g in range(self.n_generations):
            objs = []
            for i, chrom in enumerate(population):
                if last_eval[i] is None:
                    last_eval[i] = self.evaluate(chrom)
                objs.append(last_eval[i].objectives)

            fronts = self.non_dominated_sort(objs)
            new_population: List[PortfolioChromosome] = []
            new_last_eval: List[AllocationResult] = []

            for front in fronts:
                if len(new_population) + len(front) <= self.pop_size:
                    for idx in front:
                        new_population.append(population[idx])
                        new_last_eval.append(last_eval[idx])
                else:
                    dist = self.crowding_distance(front, objs)
                    order = sorted(range(len(front)), key=lambda t: dist[t], reverse=True)
                    for t in order:
                        if len(new_population) < self.pop_size:
                            idx = front[t]
                            new_population.append(population[idx])
                            new_last_eval.append(last_eval[idx])
                        else:
                            break
                if len(new_population) >= self.pop_size:
                    break

            # Offspring
            offspring: List[PortfolioChromosome] = []
            while len(offspring) < self.pop_size:
                p1 = random.choice(new_population)
                p2 = random.choice(new_population)
                if random.random() < self.crossover_prob:
                    child = self.crossover(p1, p2)
                else:
                    child = copy.deepcopy(p1)
                parent_eval = random.choice(new_last_eval)
                child = self.mutate(child, parent_eval.bottleneck_nodes if parent_eval else [])
                offspring.append(child)

            # Combine & select
            combined = new_population + offspring
            combined_eval: List[AllocationResult] = []
            combined_objs: List[Tuple[float, float, float]] = []
            for i, chrom in enumerate(combined):
                res = self.evaluate(chrom)
                combined_eval.append(res)
                combined_objs.append(res.objectives)

            fronts2 = self.non_dominated_sort(combined_objs)
            population = []
            last_eval = []
            for front in fronts2:
                if len(population) + len(front) <= self.pop_size:
                    for idx in front:
                        population.append(combined[idx])
                        last_eval.append(combined_eval[idx])
                else:
                    dist = self.crowding_distance(front, combined_objs)
                    order = sorted(range(len(front)), key=lambda t: dist[t], reverse=True)
                    for t in order:
                        if len(population) < self.pop_size:
                            idx = front[t]
                            population.append(combined[idx])
                            last_eval.append(combined_eval[idx])
                        else:
                            break
                if len(population) >= self.pop_size:
                    break

            if (g+1) % 10 == 0:
                pf_size = len(fronts2[0]) if fronts2 else 0
                print(f"Generation {g+1}: Pareto front size = {pf_size}")

        # Final Pareto (first front)
        final_objs = [ev.objectives for ev in last_eval]
        final_fronts = self.non_dominated_sort(final_objs)
        pareto_solutions: List[Tuple[DecisionVariables, Tuple[float, float, float]]] = []
        if final_fronts:
            for idx in final_fronts[0]:
                pareto_solutions.append((last_eval[idx].dv, last_eval[idx].objectives))
        return pareto_solutions

# =========================
# Excel reader & network builder
# =========================

class ExcelDataReader:
    """Read network data from Excel"""
    def __init__(self, filepath: str):
        self.filepath = filepath
        self.df_dict = {}

    def read_all_sheets(self):
        try:
            xls = pd.ExcelFile(self.filepath)
            for sheet_name in xls.sheet_names:
                self.df_dict[sheet_name] = pd.read_excel(self.filepath, sheet_name=sheet_name)
            print(f"Read file: {self.filepath}")
            print(f"Sheets: {', '.join(xls.sheet_names)}")
        except Exception as e:
            print(f"Error reading Excel: {e}")
            raise

    def normalize_name(self, name) -> str:
        if pd.isna(name) or not name:
            return ""
        name = str(name).strip()
        name = re.sub(r'\s+', ' ', name)
        return name

    def load_network_parameters(self) -> NetworkParameters:
        params = NetworkParameters()

        # Speeds (km/h): operational averages
        params.V_m = {Mode.ROAD: 45.0, Mode.RAIL: 40.0, Mode.WATER: 32.0}

        # Regional carbon prices
        params.CT_r = {'CN': 10.0, 'CA': 15.0, 'RU': 5.0, 'EE': 20.0, 'WE': 25.0}

        # Emission factors (tCO2 / TEU-km; relative scale)
        for mode in Mode:
            for region in ['CN', 'CA', 'RU', 'EE', 'WE']:
                if mode == Mode.ROAD:
                    params.E_mr[(mode, region)] = 0.09
                elif mode == Mode.RAIL:
                    params.E_mr[(mode, region)] = 0.02
                else:
                    params.E_mr[(mode, region)] = 0.012

        # Policy multipliers (ETS/subsidies, etc.)
        params.Theta_rm = {
            ('CN', Mode.ROAD): 1.0, ('CN', Mode.RAIL): 1.0, ('CN', Mode.WATER): 1.0,
            ('CA', Mode.ROAD): 1.0, ('CA', Mode.RAIL): 0.8, ('CA', Mode.WATER): 1.0,
            ('RU', Mode.ROAD): 1.0, ('RU', Mode.RAIL): 1.0, ('RU', Mode.WATER): 1.0,
            ('EE', Mode.ROAD): 1.0, ('EE', Mode.RAIL): 1.0, ('EE', Mode.WATER): 1.0,
            ('WE', Mode.ROAD): 1.0, ('WE', Mode.RAIL): 1.0, ('WE', Mode.WATER): 1.0,
        }

        # Mode-change times (hours; node-specific entries may override)
        for m1 in Mode:
            for m2 in Mode:
                if m1 != m2:
                    params.TC_jmn[(None, m1, m2)] = 50.0
                    if m1 == Mode.ROAD and m2 == Mode.RAIL:
                        params.TT_jmn[(None, m1, m2)] = 2.0
                    elif m1 == Mode.ROAD and m2 == Mode.WATER:
                        params.TT_jmn[(None, m1, m2)] = 3.0
                    elif m1 == Mode.RAIL and m2 == Mode.ROAD:
                        params.TT_jmn[(None, m1, m2)] = 2.0
                    elif m1 == Mode.RAIL and m2 == Mode.WATER:
                        params.TT_jmn[(None, m1, m2)] = 4.0
                    elif m1 == Mode.WATER and m2 == Mode.ROAD:
                        params.TT_jmn[(None, m1, m2)] = 3.0
                    elif m1 == Mode.WATER and m2 == Mode.RAIL:
                        params.TT_jmn[(None, m1, m2)] = 4.0

        # Default weights
        for node in self.get_all_nodes():
            params.W_hold[node] = 2.0
            params.W_proc[node] = 5.0
            params.W_cong[node] = 10.0
            params.BD_j[node] = 6.0
            params.CC_j[node] = 4.0
        for k in range(1, 200):
            params.P_k[k] = 20.0
        return params

    def get_all_nodes(self) -> Set[str]:
        nodes = set()
        if 'Nodes' in self.df_dict:
            df = self.df_dict['Nodes']
            for col in ['EnglishName', 'ChineseName', 'Name']:
                if col in df.columns:
                    for name in df[col]:
                        name = self.normalize_name(name)
                        if name:
                            nodes.add(name)
        for sheet_name, df in self.df_dict.items():
            if 'Arcs' in sheet_name or 'Arc' in sheet_name:
                for col in ['OriginEN', 'DestEN', 'Origin', 'Destination', 'From', 'To']:
                    if col in df.columns:
                        for name in df[col]:
                            name = self.normalize_name(name)
                            if name:
                                nodes.add(name)
        # Add whitelisted ports if absent in Excel
        nodes |= SEA_PORTS_CN | SEA_PORTS_EU
        return nodes

    def load_nodes(self) -> Dict[str, dict]:
        nodes = {}
        if 'Nodes' in self.df_dict:
            df = self.df_dict['Nodes']
            for _, row in df.iterrows():
                name = None
                for col in ['EnglishName', 'Name', 'NodeName']:
                    if col in df.columns:
                        name = self.normalize_name(row[col])
                        if name:
                            break
                if not name:
                    continue
                region = 'CN'
                if 'Region' in df.columns and not pd.isna(row['Region']):
                    region = str(row['Region']).strip()
                capacity = 1e6
                for col in ['NodeCap_TEUh', 'Capacity', 'Cap']:
                    if col in df.columns and not pd.isna(row[col]):
                        capacity = float(row[col])
                        break
                nodes[name] = {
                    'region': region,
                    'capacity': capacity
                }
                border_keywords = ['Khorgos', 'Alashankou', 'Erenhot', 'Manzhouli',
                                   'Zabaikalsk', 'Brest', 'Malaszewicze', 'Małaszewicze']
                is_border = any(kw.lower() in name.lower() for kw in border_keywords)
                nodes[name]['is_border'] = is_border

        # Ensure whitelist ports exist
        for p in (SEA_PORTS_CN | SEA_PORTS_EU):
            if p not in nodes:
                nodes[p] = {'region': ('CN' if p in SEA_PORTS_CN else 'WE'), 'capacity': 1e6, 'is_border': False}

        # Flag ports
        for name in list(nodes.keys()):
            is_port = (name in SEA_PORTS_CN) or (name in SEA_PORTS_EU)
            nodes[name]['is_port'] = is_port

        print(f"Loaded {len(nodes)} nodes")
        return nodes

    def load_arcs(self) -> Dict[Tuple[str, str], dict]:
        arcs = {}
        arc_sheets = [name for name in self.df_dict.keys() if 'Arc' in name or 'arc' in name]
        for sheet_name in arc_sheets:
            df = self.df_dict[sheet_name]
            for _, row in df.iterrows():
                origin = None
                dest = None
                for orig_col in ['OriginEN', 'Origin', 'From']:
                    if orig_col in df.columns:
                        origin = self.normalize_name(row[orig_col])
                        if origin:
                            break
                for dest_col in ['DestEN', 'Destination', 'Dest', 'To']:
                    if dest_col in df.columns:
                        dest = self.normalize_name(row[dest_col])
                        if dest:
                            break
                if not origin or not dest:
                    continue
                arc_key = (origin, dest)
                if arc_key not in arcs:
                    arcs[arc_key] = {'distances': {}, 'modes': []}
                mode_cols = {
                    'Road_km': Mode.ROAD, 'Rail_km': Mode.RAIL, 'Water_km': Mode.WATER,
                    'Road': Mode.ROAD, 'Rail': Mode.RAIL, 'Water': Mode.WATER, 'Waterway': Mode.WATER
                }
                for col, mode in mode_cols.items():
                    if col in df.columns and not pd.isna(row[col]):
                        distance = float(row[col])
                        if distance > 0:
                            arcs[arc_key]['distances'][mode] = distance
                            if mode not in arcs[arc_key]['modes']:
                                arcs[arc_key]['modes'].append(mode)
        print(f"Loaded {len(arcs)} arcs")
        return arcs

    def load_schedules(self) -> Dict[Tuple[str, str, Mode], float]:
        schedules = {}
        if 'Timetable' in self.df_dict:
            df = self.df_dict['Timetable']
            for _, row in df.iterrows():
                origin = self.normalize_name(row.get('OriginEN', ''))
                dest = self.normalize_name(row.get('DestEN', ''))
                if not origin or not dest:
                    continue
                freq_str = row.get('Frequency_per_week', None)
                if pd.isna(freq_str):
                    continue
                freq = self.parse_frequency(str(freq_str))
                if freq and freq > 0:
                    headway = 168.0 / freq
                    mode_str = str(row.get('Mode', '')).strip().upper() if 'Mode' in df.columns else ''
                    if 'RAIL' in mode_str or mode_str == '2':
                        schedules[(origin, dest, Mode.RAIL)] = headway
                    elif 'WATER' in mode_str or mode_str == '3':
                        schedules[(origin, dest, Mode.WATER)] = headway
                    else:
                        schedules[(origin, dest, Mode.RAIL)] = headway
                        schedules[(origin, dest, Mode.WATER)] = headway
        print(f"Loaded {len(schedules)} service headways")
        return schedules

    def parse_frequency(self, freq_str: str) -> Optional[float]:
        freq_str = freq_str.lower()
        if 'daily' in freq_str:
            return 7.0
        elif 'weekly' in freq_str:
            return 1.0
        elif 'biweekly' in freq_str:
            return 0.5
        else:
            numbers = re.findall(r'\d+(?:\.\d+)?', freq_str)
            if numbers:
                return float(numbers[0])
        return None

    # === Auto-inject common sea trunks and rail feeders ===
    def _ensure_sea_connectivity(self, nodes, arcs, params):
        # 1) CN–EU common port-to-port sea trunks (approx distances, km)
        sea_pairs_km = {
            ("Shanghai","Hamburg"): 20300, ("Shanghai","Rotterdam"): 19600, ("Shanghai","Antwerp"): 19850,
            ("Ningbo","Hamburg"): 19900, ("Qingdao","Hamburg"): 18800, ("Tianjin","Hamburg"): 19700,
            ("Shenzhen","Hamburg"): 20800, ("Xiamen","Hamburg"): 20500,
            ("Shanghai","Piraeus"): 17600, ("Ningbo","Piraeus"): 17200, ("Shenzhen","Piraeus"): 18100,
        }
        for (o,d), dist in sea_pairs_km.items():
            if o in nodes and d in nodes:
                for key in [(o,d),(d,o)]:
                    if key not in arcs:
                        arcs[key] = {'distances': {Mode.WATER: float(dist)}, 'modes': [Mode.WATER]}
                    else:
                        arcs[key]['distances'][Mode.WATER] = float(dist)
                        if Mode.WATER not in arcs[key]['modes']:
                            arcs[key]['modes'].append(Mode.WATER)
                # Minimal weekly sea departures to trigger waiting
                for port in [o,d]:
                    if (port, Mode.WATER) not in params.S_jm or not params.S_jm.get((port, Mode.WATER)):
                        params.S_jm[(port, Mode.WATER)] = [0.0]

        # 2) China inland hubs → CN ports (rail feeders; approx)
        feeder_cn = {
            "Xi'an": {"Qingdao":1500, "Shanghai":1600},
            "Chongqing": {"Shanghai":1700, "Shenzhen":1600},
            "Zhengzhou": {"Qingdao":850, "Shanghai":1000},
            "Wuhan": {"Shanghai":900, "Shenzhen":1000},
        }
        for i, dmap in feeder_cn.items():
            if i not in nodes: 
                continue
            for j, dist in dmap.items():
                if j in nodes:
                    key = (i,j)
                    if key not in arcs:
                        arcs[key] = {'distances': {Mode.RAIL: float(dist)}, 'modes': [Mode.RAIL]}
                    else:
                        arcs[key]['distances'][Mode.RAIL] = float(dist)
                        if Mode.RAIL not in arcs[key]['modes']:
                            arcs[key]['modes'].append(Mode.RAIL)

        # 3) EU ports → inland destinations (rail feeders; approx)
        feeder_eu_rail = {
            "Hamburg": {"Berlin":290, "Duisburg":380, "Munich":790},
            "Rotterdam": {"Duisburg":230, "Berlin":680},
            "Antwerp": {"Duisburg":220}
        }
        for i, dmap in feeder_eu_rail.items():
            if i not in nodes: 
                continue
            for j, dist in dmap.items():
                if j in nodes:
                    key = (i,j)
                    if key not in arcs:
                        arcs[key] = {'distances': {Mode.RAIL: float(dist)}, 'modes': [Mode.RAIL]}
                    else:
                        arcs[key]['distances'][Mode.RAIL] = float(dist)
                        if Mode.RAIL not in arcs[key]['modes']:
                            arcs[key]['modes'].append(Mode.RAIL)

        # 4) Maintain params.arc_modes
        for (o,d), data in arcs.items():
            params.arc_modes[(o,d)] = data['modes']

    def build_network_data(self) -> Tuple[NetworkParameters, dict]:
        self.read_all_sheets()
        nodes = self.load_nodes()
        arcs = self.load_arcs()
        schedules = self.load_schedules()
        params = self.load_network_parameters()

        # Map node attributes
        for node_name, node_data in nodes.items():
            params.rho[node_name] = node_data['region']
            params.CAP_node[node_name] = float(node_data['capacity'])  # TEU/h
            params.B_j[node_name] = node_data.get('is_border', False)

        # Map arc attributes & unit costs
        for (origin, dest), arc_data in arcs.items():
            for mode, distance in arc_data['distances'].items():
                params.L_ij[(origin, dest)] = distance
                if mode == Mode.ROAD:
                    params.C_ijm[(origin, dest, mode)] = 3.2
                elif mode == Mode.RAIL:
                    params.C_ijm[(origin, dest, mode)] = 1.0
                else:
                    params.C_ijm[(origin, dest, mode)] = 0.6
            params.arc_modes[(origin, dest)] = arc_data['modes']
            if origin in nodes and dest in nodes:
                if nodes[origin]['region'] != nodes[dest]['region']:
                    params.I_border[(origin, dest)] = True

        # Build weekly departure times from headways
        for (origin, dest, mode), headway in schedules.items():
            schedule_times = []
            t = 0.0
            while t < 168.0:
                schedule_times.append(round(t, 6))
                t += headway
            key = (origin, mode)
            if key not in params.S_jm:
                params.S_jm[key] = schedule_times
            else:
                merged = sorted(set(params.S_jm[key] + schedule_times))
                params.S_jm[key] = merged

        # Inject sea & feeders if missing
        self._ensure_sea_connectivity(nodes, arcs, params)

        network = {'nodes': nodes, 'arcs': arcs, 'schedules': schedules}

        # Optional: unify capacities for experiments
        # for j in params.CAP_node.keys():
        #     params.CAP_node[j] = 250.0

        return params, network

# ========= Detailed allocation report (node view) =========

def build_allocation_report(model: MultimodalOptimizationModel,
                            dv: DecisionVariables) -> str:
    params = model.params
    aux = AuxiliaryVariables()
    aux.y_jmnk = model.determine_transshipment_volumes(dv)

    node_throughput = defaultdict(float)
    node_throughput_by_batch = defaultdict(float)

    for (i, j, m, k), flow in dv.f_ijmk.items():
        if flow > 0:
            node_throughput[j] += flow
            node_throughput_by_batch[(j, k)] += flow

    batch_node_splits = defaultdict(lambda: defaultdict(list))
    for (j, m, n, k), y in aux.y_jmnk.items():
        if y > 1e-9:
            batch_node_splits[k][j].append((m, n, y))

    lines = []
    lines.append("\nDetailed allocation & transhipment")
    lines.append("-" * 80)

    for b in model.batches:
        lines.append(f"\nBatch {b.id}: {b.O_k} -> {b.DEST_k}, demand={b.Q_k:.2f} TEU")
        has_flow = any(k2 == b.id and f > 0 for (_, _, _, k2), f in dv.f_ijmk.items())
        if not has_flow:
            lines.append("  * Not allocated (infeasible pool or capacity conflict)")
            continue

        if b.id in batch_node_splits:
            for j, items in batch_node_splits[b.id].items():
                cap = params.CAP_node.get(j, float('inf'))
                batch_through = node_throughput_by_batch.get((j, b.id), 0.0)
                lines.append(f"  - Node {j}: capacity={cap:.2f} TEU/h, batch throughput={batch_through:.2f} TEU")
                for (m, n, y) in sorted(items, key=lambda x: -x[2]):
                    lines.append(f"      · Mode change: {Mode(m).name} → {Mode(n).name}, volume={y:.2f} TEU")
        else:
            lines.append("  * No mode change (single-mode or direct path)")

    lines.append("\nNode throughput overview (all batches aggregated)")
    lines.append("-" * 80)
    for j, tot in sorted(node_throughput.items(), key=lambda x: -x[1]):
        cap = params.CAP_node.get(j, float('inf'))
        lines.append(f"  Node {j}: capacity={cap:.2f} TEU/h, throughput={tot:.2f} TEU")

    return "\n".join(lines)

# ========= Route decomposition (per batch) =========

def _decompose_batch_paths(model: MultimodalOptimizationModel,
                           dv: DecisionVariables,
                           batch: Batch) -> List[Tuple[List[str], List[Mode], float]]:
    flow = defaultdict(float)  # key=(i,j,m)
    for (i, j, m, k), v in dv.f_ijmk.items():
        if k == batch.id and v > 1e-9:
            flow[(i, j, m)] += v

    def build_adj():
        adj = defaultdict(list)
        for (i, j, m), v in flow.items():
            if v > 1e-9:
                adj[i].append((j, m, v))
        return adj

    paths = []
    while True:
        adj = build_adj()
        if batch.O_k not in adj:
            break

        best_path_nodes = None
        best_path_modes = None
        stack = [(batch.O_k, [batch.O_k], [])]
        found = False
        while stack and not found:
            node, nodes, modes = stack.pop()
            if node == batch.DEST_k and len(nodes) > 1:
                best_path_nodes = nodes
                best_path_modes = modes
                found = True
                break
            for (j, m, v) in adj.get(node, []):
                if j in nodes:
                    continue
                stack.append((j, nodes + [j], modes + [m]))

        if not found:
            break

        min_edge = float('inf')
        for a, b, m in zip(best_path_nodes[:-1], best_path_nodes[1:], best_path_modes):
            min_edge = min(min_edge, flow[(a, b, m)])
        if min_edge < 1e-9 or min_edge == float('inf'):
            break

        paths.append((best_path_nodes, best_path_modes, min_edge))
        for a, b, m in zip(best_path_nodes[:-1], best_path_nodes[1:], best_path_modes):
            flow[(a, b, m)] -= min_edge

    return paths


def build_route_report(model: MultimodalOptimizationModel, dv: DecisionVariables) -> str:
    params = model.params
    aux = AuxiliaryVariables()
    aux.y_jmnk = model.determine_transshipment_volumes(dv)

    batch_node_in = defaultdict(float)
    for (i, j, m, k), v in dv.f_ijmk.items():
        if v > 0:
            batch_node_in[(k, j)] += v

    lines = []
    lines.append("\nFull route decomposition (per batch)")
    lines.append("-" * 80)

    for b in model.batches:
        paths = _decompose_batch_paths(model, dv, b)
        lines.append(f"\nBatch {b.id}: {b.O_k} -> {b.DEST_k}, demand={b.Q_k:.2f} TEU")
        if not paths:
            lines.append("  * No complete O→D path found (flows fragmented or unreachable)")
            continue

        tot = sum(p[2] for p in paths)
        lines.append(f"  · Number of paths={len(paths)}, total allocated≈{tot:.2f} TEU")
        for idx, (nodes, modes, q) in enumerate(paths, 1):
            steps = []
            for a, b2, m in zip(nodes[:-1], nodes[1:], modes):
                steps.append(f"{a} —[{Mode(m).name}]→ {b2}")
            route_str = "  ->  ".join(steps)
            lines.append(f"    Path {idx}: {route_str}  | volume={q:.2f} TEU")

        splits = [(j, m, n, k, y) for (j, m, n, k), y in aux.y_jmnk.items() if k == b.id and y > 1e-9]
        if splits:
            lines.append("  · Mode-change nodes:")
            for (j, m, n, _, y) in sorted(splits, key=lambda x: -x[4]):
                cap = params.CAP_node.get(j, float('inf'))
                thr = batch_node_in.get((b.id, j), 0.0)
                lines.append(f"      {j}: {Mode(m).name}→{Mode(n).name}, volume={y:.2f} TEU; "
                             f"node cap={cap:.2f} TEU/h, batch throughput here={thr:.2f} TEU")
        else:
            lines.append("  · No mode changes")

    return "\n".join(lines)

# =========================
# Main
# =========================

def main():
    """Run the two-level NSGA-II optimisation"""
    import sys

    possible_paths = [
        'extended.xlsx',
        'Low Carbon/extended.xlsx',
        'low carbon/extended.xlsx',
        '../Low Carbon/extended.xlsx',
        '../extended.xlsx'
    ]
    excel_file = None
    for path in possible_paths:
        if os.path.exists(path):
            excel_file = path
            break
    if not excel_file:
        print("Error: extended.xlsx not found")
        print("Please place the file in one of:")
        for path in possible_paths:
            print(f"  - {path}")
        sys.exit(1)

    print(f"Using file: {excel_file}")
    print("="*80)
    reader = ExcelDataReader(excel_file)
    params, network = reader.build_network_data()

    # Build batches
    batches: List[Batch] = []
    major_origins = ["Xi'an", "Chongqing", "Zhengzhou", "Wuhan"]
    major_destinations = ["Berlin", "Hamburg", "Duisburg", "Munich"]
    batch_id = 1
    for origin in major_origins:
        for dest in major_destinations:
            if origin in network['nodes'] and dest in network['nodes']:
                batch = Batch(
                    id=batch_id,
                    O_k=origin,
                    DEST_k=dest,
                    Q_k=random.uniform(50, 150),
                    ET_k=0.0,
                    LT_k=960.0  # 40 days horizon by default
                )
                batches.append(batch)
                batch_id += 1
    if not batches:
        all_nodes = list(network['nodes'].keys())
        cn_nodes = [n for n in all_nodes if network['nodes'][n]['region'] == 'CN']
        eu_nodes = [n for n in all_nodes if network['nodes'][n]['region'] in ['WE', 'EE']]
        if cn_nodes and eu_nodes:
            for i in range(min(3, len(cn_nodes))):
                for j in range(min(3, len(eu_nodes))):
                    batch = Batch(
                        id=i*3+j+1,
                        O_k=cn_nodes[i],
                        DEST_k=eu_nodes[j],
                        Q_k=100.0,
                        ET_k=0.0,
                        LT_k=960.0
                    )
                    batches.append(batch)

    print(f"Created {len(batches)} batches:")
    for batch in batches[:12]:
        print(f"  Batch {batch.id}: {batch.O_k} -> {batch.DEST_k}, {batch.Q_k:.1f} TEU")
    if len(batches) > 12:
        print(f"  ... (remaining {len(batches)-12} omitted)")

    print("\nStarting two-level optimisation...")
    print("="*80)
    model = MultimodalOptimizationModel(params, network, batches)

    # Two-Level NSGA-II
    tl_nsga2 = TwoLevelNSGA2(
        model=model,
        batches=batches,
        pop_size=30,
        n_generations=50,
        crossover_prob=0.9,
        mutation_prob=0.25,
        max_paths_per_od=3
    )
    pareto_solutions = tl_nsga2.run()

    print("\n" + "="*80)
    print("Pareto-optimal solutions")
    print("="*80)
    if pareto_solutions:
        pareto_solutions.sort(key=lambda x: x[1][0])   # Show top-10 by cost
        for i, (solution, objectives) in enumerate(pareto_solutions[:10], 1):
            print(f"\nSolution {i}:")
            print(f"  Objective 1 – Total cost: ${objectives[0]:,.2f}")
            print(f"  Objective 2 – Total emissions: {objectives[1]:.2f} tCO2")
            print(f"  Objective 3 – Completion time: {objectives[2]:.2f} h ({objectives[2]/24:.1f} days)")
    else:
        print("No feasible solution found. Please check network connectivity/data quality.")

    # Write report
    output_file = 'optimisation_results.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("Multi-batch multimodal network optimisation results (two-level NSGA-II)\n")
        f.write("="*80 + "\n\n")
        f.write(f"Data source: {excel_file}\n")
        f.write(f"Number of batches: {len(batches)}\n")
        f.write(f"Number of nodes: {len(network['nodes'])}\n")
        f.write(f"Number of arcs: {len(network['arcs'])}\n\n")
        if pareto_solutions:
            f.write("Pareto front:\n")
            for i, (_, objectives) in enumerate(pareto_solutions, 1):
                f.write(f"Solution {i}: cost=${objectives[0]:.2f}, emissions={objectives[1]:.2f} tCO2, time={objectives[2]:.2f} h\n")

            # Pick the lowest-cost solution for detailed reports
            best_sol_dv, _ = sorted(pareto_solutions, key=lambda x: x[1][0])[0]
            detail_report = build_allocation_report(model, best_sol_dv)
            f.write("\n")
            f.write(detail_report)

            route_report = build_route_report(model, best_sol_dv)
            f.write("\n")
            f.write(route_report)

    print(f"\nResults saved to: {output_file}")

if __name__ == "__main__":
    main()
